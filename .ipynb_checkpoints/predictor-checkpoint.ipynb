{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 150)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "\n",
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import requests\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for judging a description\n",
    "not_flowing_keywords = [\"dry\", \"no water\", \"no flow\", \"not \"]\n",
    "def isNotFlowing(description):\n",
    "    return any([kw in description for kw in not_flowing_keywords])\n",
    "assert(isNotFlowing(\"looks dry\"))\n",
    "\n",
    "flowing_keywords = [\"good\", \"flowing\", \"flow\", \"lots\", \"working\"]\n",
    "def isFlowing(description):\n",
    "    return any([kw in description for kw in flowing_keywords])\n",
    "assert(isFlowing(\"flowing well\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that tries to fix a location id, leaves non-waypoint labels alone in case they are in the gps data\n",
    "# fixes the leading zeros problem WR004 = WR0004\n",
    "def clean_loc_id(id):\n",
    "    try:\n",
    "        waypoint_search = re.search('((?:WR|WA)(?:CS|))([0-9]+)', id, re.IGNORECASE)\n",
    "\n",
    "        if waypoint_search:        \n",
    "            waypoint_type = waypoint_search.group(1)\n",
    "            waypoint_num = waypoint_search.group(2)\n",
    "\n",
    "            return f\"{waypoint_type}{int(waypoint_num):04}\"\n",
    "    except:\n",
    "        return id\n",
    "    return id\n",
    "assert(clean_loc_id(\"WR004\") == \"WR0004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for finding the last positive result and last negative result\n",
    "def last_pos(row):\n",
    "    last_pos_date = data[(data.loc_id == row.loc_id) & (data.status==1) & (data.date < row.date)].date.max()\n",
    "    if type(last_pos_date) == float:\n",
    "        return 1000\n",
    "    return (row.date - last_pos_date).days\n",
    "    \n",
    "def last_neg(row):\n",
    "    last_neg_date = data[(data.loc_id == row.loc_id) & (data.status==0) & (data.date < row.date)].date.max()    \n",
    "    if type(last_neg_date) == float:\n",
    "        return 1000\n",
    "    return (row.date - last_neg_date).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a lat, lon, and name dictionaries keyed on loc_ids \n",
    "waypoints = []\n",
    "for path in glob.glob(\"gps/*.gpx\"):\n",
    "    gpx_file = open(path, 'r')\n",
    "    gpx = gpxpy.parse(gpx_file)\n",
    "    waypoints += (gpx.waypoints)\n",
    "    \n",
    "lat = {clean_loc_id(wp.name):wp.latitude for wp in waypoints}\n",
    "lon = {clean_loc_id(wp.name):wp.longitude for wp in waypoints}\n",
    "name = {clean_loc_id(wp.name):wp.description for wp in waypoints}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a generator for sequentially reading in the data\n",
    "def data_generator():\n",
    "    for f in glob.glob(\"pct_data/*.xlsx\"):\n",
    "        data = pd.read_excel(f).dropna()\n",
    "        _,cols = data.shape\n",
    "        if cols == 7:\n",
    "            data.columns = [\"map\",\"mile\",\"loc_id\",\"loc\", \"description\", \"date\", \"user\"]\n",
    "        if cols == 8:\n",
    "            data.columns = [\"map\",\"mile_2\",\"mile\",\"loc_id\",\"loc\", \"description\", \"date\", \"user\"]\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# import and combine data\n",
    "data = pd.concat(data_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the descriptions\n",
    "data.description = data.description.str.split(\"\\n\").str[0].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the lod_ids\n",
    "data.loc_id = data.loc_id.apply(clean_loc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a unix time column\n",
    "data[\"unix_time\"] = (pd.to_datetime(data[\"date\"], errors='coerce').astype(np.int64)//1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lat and lon columns\n",
    "data[\"lat\"] = data[\"loc_id\"].map(lat)\n",
    "data[\"lon\"] = data[\"loc_id\"].map(lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create not_flowing and flowing columns\n",
    "data[\"not_flowing\"] = data[\"description\"].map(isNotFlowing, na_action=\"ignore\")\n",
    "data[\"flowing\"] = data[\"description\"].map(isFlowing, na_action=\"ignore\")\n",
    "data[\"decision\"] = data.flowing|data.not_flowing\n",
    "data[\"status\"] = data.flowing.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate entries (ones with the same date and loc_id)\n",
    "data = data.drop_duplicates(subset=[\"date\",\"loc_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all data with no decision\n",
    "data = data[data.decision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create last positive and negative result columns\n",
    "data[\"last_pos\"] = data.apply(last_pos, axis=1)\n",
    "data[\"last_neg\"] = data.apply(last_neg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop data with missing coordinates\n",
    "data = data.dropna(subset=[\"lat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_ids = list(data.groupby(\"loc_id\").nunique().sort_values(by=\"date\")[-50:].loc_id.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.loc_id.isin(loc_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1083, 17)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('rain.pkl', 'rb')   # Pickle file is newly created where foo1.py is\n",
    "rain = pickle.load(f)\n",
    "f.close() \n",
    "def getRainfall(lat, lon, time):\n",
    "    rainfalls = []\n",
    "    for days in range(n_days):\n",
    "        r = requests.get(f\"https://api.darksky.net/forecast/840fdc3fb61acc3d4e904978b5ba8dc5/{lat},{lon},{time-(days*24*60*60)}\")\n",
    "        rainfalls.append(r.json()[\"daily\"][\"data\"][0][\"precipIntensity\"])\n",
    "    return rainfalls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
